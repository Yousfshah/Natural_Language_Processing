{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "208c0afb",
   "metadata": {},
   "source": [
    "<h1 style=\"\n",
    "  font-size: 3.2rem;\n",
    "  font-weight: 900;\n",
    "  text-align: center;\n",
    "  margin: 3rem auto 2rem;\n",
    "  padding: 1rem 1.5rem;\n",
    "  background: linear-gradient(90deg, #00c3ff, #ff69b4, #00c3ff);\n",
    "  background-size: 300% auto;\n",
    "  color: transparent;\n",
    "  background-clip: text;\n",
    "  -webkit-background-clip: text;\n",
    "  -webkit-text-fill-color: transparent;\n",
    "  animation: moveGradient 6s ease-in-out infinite, pulseShadow 2s infinite;\n",
    "  font-family: 'Segoe UI', 'Lato', sans-serif;\n",
    "  text-shadow: 0 0 12px rgba(255,255,255,0.3), 0 0 22px rgba(255, 0, 200, 0.3);\n",
    "  position: relative;\n",
    "  transition: transform 0.4s ease;\n",
    "  cursor: default;\n",
    "\">\n",
    "  ‚ú® Text Preprocessing\n",
    "  <span style=\"\n",
    "    position: absolute;\n",
    "    bottom: -12px;\n",
    "    left: 50%;\n",
    "    transform: translateX(-50%);\n",
    "    height: 6px;\n",
    "    width: 92%;\n",
    "    background: linear-gradient(to right, #ff0066, #ffcc00);\n",
    "    border-radius: 4px;\n",
    "    box-shadow: 0 0 10px rgba(255, 0, 128, 0.7), 0 0 14px rgba(255, 204, 0, 0.6);\n",
    "  \"></span>\n",
    "</h1>\n",
    "\n",
    "<style>\n",
    "@keyframes moveGradient {\n",
    "  0% {\n",
    "    background-position: 0% center;\n",
    "  }\n",
    "  50% {\n",
    "    background-position: 100% center;\n",
    "  }\n",
    "  100% {\n",
    "    background-position: 0% center;\n",
    "  }\n",
    "}\n",
    "\n",
    "@keyframes pulseShadow {\n",
    "  0% {\n",
    "    text-shadow: 0 0 12px rgba(255,255,255,0.3), 0 0 22px rgba(255, 0, 200, 0.3);\n",
    "  }\n",
    "  50% {\n",
    "    text-shadow: 0 0 18px rgba(255,255,255,0.6), 0 0 28px rgba(255, 0, 200, 0.5);\n",
    "  }\n",
    "  100% {\n",
    "    text-shadow: 0 0 12px rgba(255,255,255,0.3), 0 0 22px rgba(255, 0, 200, 0.3);\n",
    "  }\n",
    "}\n",
    "</style>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd81ad6",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"./Banners/Banner_img.png\" \n",
    "       alt=\"Text Preprocessing Steps\" \n",
    "       style=\"max-width: 60%; height: 50%; border-radius: 20px; border: 5px solid yellow;\" />\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c7b249",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 42rem; margin: 2.5rem auto; padding: 2rem; text-align: center; background: linear-gradient(135deg, #8d8d8dff, #9c9b9bff); box-shadow: 0 0.5rem 1.25rem rgba(0, 0, 0, 0.15); font-family: 'Lato', Arial, sans-serif; border: 5px solid black; border-radius: 0.75rem;\">\n",
    "\n",
    "  <h3 style=\"font-size: 1.5rem; font-weight: 700; margin-bottom: 1.5rem; color: #000000; letter-spacing: 0.05em;\">\n",
    "    <strong style=\"color: #000;\">Author Name:</strong>\n",
    "    <a href=\"https://www.linkedin.com/in/yousuf-shah-7ba9492b4/\" \n",
    "       style=\"color: #ab1700ff; text-decoration: none; font-weight: bold; transition: all 0.3s;\" \n",
    "       onmouseover=\"this.style.textDecoration='underline'; this.style.textShadow='0 0 5px #ab1700ff'\" \n",
    "       onmouseout=\"this.style.textDecoration='none'; this.style.textShadow='none'\">\n",
    "       Yousuf Shah\n",
    "    </a>\n",
    "  </h3>\n",
    "\n",
    "  <div style=\"display: flex; flex-wrap: wrap; justify-content: center; gap: 1.25rem;\">\n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/yousuf-shah-7ba9492b4/\" style=\"text-decoration: none;\">\n",
    "    <img src=\"https://img.shields.io/badge/LinkedIn-Connect-0a66c2?style=for-the-badge&logo=linkedin&logoColor=white\"\n",
    "        alt=\"LinkedIn\"\n",
    "        style=\"height: 3.3rem; padding: 0.3rem; background: #000; transition: transform 0.3s;\"\n",
    "        onmouseover=\"this.style.transform='scale(1.07)'\" \n",
    "        onmouseout=\"this.style.transform='scale(1)'\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://yousfshah.github.io/Portfolio_Website/\" style=\"text-decoration: none;\">\n",
    "    <img src=\"https://img.shields.io/badge/Portfolio-Visit-ffb300?style=for-the-badge&logo=firefox&logoColor=white\"\n",
    "        alt=\"Portfolio\"\n",
    "        style=\"height: 3.3rem; padding: 0.3rem; background: #000; transition: transform 0.3s;\"\n",
    "        onmouseover=\"this.style.transform='scale(1.07)'\" \n",
    "        onmouseout=\"this.style.transform='scale(1)'\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://github.com/Yousfshah\" style=\"text-decoration: none;\">\n",
    "    <img src=\"https://img.shields.io/badge/GitHub-Explore-6f42c1?style=for-the-badge&logo=github&logoColor=white\"\n",
    "        alt=\"GitHub\"\n",
    "        style=\"height: 3.3rem; padding: 0.3rem; background: #000; transition: transform 0.3s;\"\n",
    "        onmouseover=\"this.style.transform='scale(1.07)'\" \n",
    "        onmouseout=\"this.style.transform='scale(1)'\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://www.kaggle.com/yousufshah\" style=\"text-decoration: none;\">\n",
    "    <img src=\"https://img.shields.io/badge/Kaggle-Profile-0097b2?style=for-the-badge&logo=kaggle&logoColor=white\"\n",
    "        alt=\"Kaggle\"\n",
    "        style=\"height: 3.3rem; padding: 0.3rem; background: #000; transition: transform 0.3s;\"\n",
    "        onmouseover=\"this.style.transform='scale(1.07)'\" \n",
    "        onmouseout=\"this.style.transform='scale(1)'\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://yousfshah.github.io/Blogging/\" style=\"text-decoration: none;\">\n",
    "    <img src=\"https://img.shields.io/badge/Blog-Articles-f44336?style=for-the-badge&logo=blogger&logoColor=white\"\n",
    "        alt=\"Blog\"\n",
    "        style=\"height: 3.3rem; padding: 0.3rem; background: #000; transition: transform 0.3s;\"\n",
    "        onmouseover=\"this.style.transform='scale(1.07)'\" \n",
    "        onmouseout=\"this.style.transform='scale(1)'\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://x.com/YousufAnalyst\" style=\"text-decoration: none;\">\n",
    "    <img src=\"https://img.shields.io/badge/Twitter-Follow-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white\"\n",
    "        alt=\"Twitter\"\n",
    "        style=\"height: 3.3rem; padding: 0.3rem; background: linear-gradient(to right, #000, #000); transition: transform 0.3s;\"\n",
    "        onmouseover=\"this.style.transform='scale(1.07)'\" \n",
    "        onmouseout=\"this.style.transform='scale(1)'\">\n",
    "</a>\n",
    "\n",
    "  </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5910a6b4",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 2.5rem auto; padding: 2rem 2.5rem; background: linear-gradient(135deg, #8d8d8dff, #9c9b9bff); box-shadow: 0 0.75rem 1.5rem rgba(0, 0, 0, 0.08); font-family: 'Segoe UI', 'Lato', sans-serif; color: #111; border-left: 6px solid #0055ff; border-radius: 0.5rem;\">\n",
    "\n",
    "  <h3 style=\"font-size: 1.8rem; font-weight: 700; margin-bottom: 1.2rem; color: #000000ff;\">\n",
    "    üìå Why You Should Practice This Notebook\n",
    "  </h3>\n",
    "\n",
    "  <p style=\"font-size: 1.05rem; line-height: 1.7; margin-bottom: 1rem; color:#000; font-weight: bold;\">\n",
    "    If you're serious about mastering NLP, this notebook gives you a hands-on, end-to-end experience with real-world text preprocessing ‚Äî the foundation of every NLP project.\n",
    "    You'll learn to clean, normalize, and prepare raw text using both industry-standard tools (<strong>spaCy</strong> + <strong>NLTK</strong>) and best practices followed in real ML pipelines.\n",
    "  </p>\n",
    "\n",
    "  <ul style=\"font-size: 1.05rem; line-height: 1.7; padding-left: 1.2rem; margin-bottom: 1rem; color:#000; font-weight: bold;\">\n",
    "    <li>‚úÖ Practical code examples</li>\n",
    "    <li>‚úÖ Reusable functions</li>\n",
    "    <li>‚úÖ Cleaned input ready for ML, BERT, or vectorization</li>\n",
    "  </ul>\n",
    "\n",
    "  <p style=\"font-size: 1.05rem; line-height: 1.7; font-weight: 600; color: #ab1700ff;\">\n",
    "    Good models start with great preprocessing.<br>\n",
    "  </p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfb2406",
   "metadata": {},
   "source": [
    "<div style=\"margin: 2rem auto; padding: 1rem;\">\n",
    "  <hr style=\"border: none; height: 3px; background: linear-gradient(90deg, #4b0000ff, #edf500ff); width: 100%; margin: 1rem 0;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c39e823",
   "metadata": {},
   "source": [
    "<div style=\"background:linear-gradient(135deg, #8d8d8dff, #9c9b9bff); border: 5px solid linear-gradient(135deg, green, black); border:3px solid yellow; border-radius: 20px; padding:15px\">\n",
    "\n",
    "  <h2 style=\"font-weight: 700; color: #000;\">\n",
    "    1Ô∏è‚É£ Lowercasing\n",
    "  </h2>\n",
    "\n",
    "  <h3 style=\"color: #000;\">\n",
    "    üîç <strong>Why:</strong>\n",
    "  </h3>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    Words like \n",
    "    <strong style=\"color: #ab1700ff;\">Good</strong>, \n",
    "    <strong style=\"color: #ab1700ff;\">GOOD</strong>, and \n",
    "    <strong style=\"color: #ab1700ff;\">good</strong>\n",
    "    are semantically identical but are treated as separate tokens if not lowercased.\n",
    "  </p>\n",
    "\n",
    "  <h4 style=\"color: #000;\">\n",
    "    üìå <strong>Real-World:</strong>\n",
    "  </h4>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    In a product review system, \n",
    "    <strong style=\"color: #ab1700ff;\">Excellent</strong> and \n",
    "    <strong style=\"color: #ab1700ff;\">excellent</strong> \n",
    "    should be considered the same sentiment word.\n",
    "  </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6cbb363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîµ Original Text:  Good Morning EVERYONE! Let's Start Our NLP Journey. \n",
      "\n",
      "üü¢ Lowercased Text:  good morning everyone! let's start our nlp journey.\n"
     ]
    }
   ],
   "source": [
    "def to_lowercase(text):\n",
    "    # Convert text to lowercase\n",
    "    if not isinstance(text, str):\n",
    "        print(\"‚ö†Ô∏è Input must be a string.\")\n",
    "        return None\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text = \"Good Morning EVERYONE! Let's Start Our NLP Journey.\"\n",
    "lowercased = to_lowercase(text)\n",
    "\n",
    "print(\"üîµ Original Text: \", text, \"\\n\")\n",
    "print(\"üü¢ Lowercased Text: \", lowercased)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d2c2c6",
   "metadata": {},
   "source": [
    "<div style=\"margin: 2rem auto; padding: 1rem;\">\n",
    "  <hr style=\"border: none; height: 3px; background: linear-gradient(90deg, #4b0000ff, #edf500ff); width: 100%; margin: 1rem 0;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea7dadc",
   "metadata": {},
   "source": [
    "<div style=\"background:linear-gradient(135deg, #8d8d8dff, #9c9b9bff); border: 5px solid linear-gradient(135deg, green, black); border:3px solid yellow; border-radius: 20px; padding:15px\">\n",
    "\n",
    "  <h2 style=\"font-weight: 700; color: #000;\">\n",
    "    2Ô∏è‚É£ Remove HTML Tags\n",
    "  </h2>\n",
    "\n",
    "  <h3 style=\"color: #000;\">\n",
    "    üîç <strong>Why:</strong>\n",
    "  </h3>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    HTML is markup used for layout, not meaning.\n",
    "  </p>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    If you're scraping websites (news, blogs), tags like <span style= color:#ab1700ff;>div, a, span tag</span> add noise.\n",
    "  </p>\n",
    "\n",
    "  <h4 style=\"color: #000;\">\n",
    "    üìå <strong>Real-World:</strong>\n",
    "  </h4>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    When extracting articles from news sites, you'll find lots of formatting tags. Models get confused by p tag, a href tag etc.\n",
    "  </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec120d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîµ Original Text:  <div>Hello <b>World</b>! NLP is <i>awesome</i>.</div> \n",
      "\n",
      "üü¢ Cleaned with BS4:  Hello World! NLP is awesome. \n",
      "\n",
      "üî¥ Cleaned with Regex:  Hello World! NLP is awesome.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "\n",
    "def remove_html_tags(text, method=\"bs4\"):\n",
    "    # Remove HTML tags using BeautifulSoup or regex\n",
    "    if not isinstance(text, str):\n",
    "        print(\"‚ö†Ô∏è Input must be a string.\")\n",
    "        return None\n",
    "\n",
    "    if method == \"bs4\":\n",
    "        return BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    elif method == \"regex\":\n",
    "        pattern = r\"<(?:\\\"[^\\\"]*\\\"['\\\"]*|'[^']*'['\\\"]*|[^'\\\">])+>\"\n",
    "        return re.sub(pattern, '', text)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Invalid method. Use 'bs4' or 'regex'.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example usage\n",
    "html_text = \"<div>Hello <b>World</b>! NLP is <i>awesome</i>.</div>\"\n",
    "\n",
    "cleaned_bs4 = remove_html_tags(html_text, method=\"bs4\")\n",
    "cleaned_regex = remove_html_tags(html_text, method=\"regex\")\n",
    "\n",
    "print(\"üîµ Original Text: \", html_text, \"\\n\")\n",
    "print(\"üü¢ Cleaned with BS4: \", cleaned_bs4, \"\\n\")\n",
    "print(\"üî¥ Cleaned with Regex: \", cleaned_regex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762f8ff7",
   "metadata": {},
   "source": [
    "<div style=\"margin: 2rem auto; padding: 1rem;\">\n",
    "  <hr style=\"border: none; height: 3px; background: linear-gradient(90deg, #4b0000ff, #edf500ff); width: 100%; margin: 1rem 0;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9400e57b",
   "metadata": {},
   "source": [
    "<div style=\"background:linear-gradient(135deg, #8d8d8dff, #9c9b9bff); border: 3px solid yellow; border-radius: 20px; padding:15px\">\n",
    "\n",
    "  <h2 style=\"font-weight: 700; color: #000;\">\n",
    "    3Ô∏è‚É£ Remove URLs\n",
    "  </h2>\n",
    "\n",
    "  <h3 style=\"color: #000;\">\n",
    "    üîç <strong>Why:</strong>\n",
    "  </h3>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    URLs usually don‚Äôt carry semantic meaning.\n",
    "  </p>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    They are high variance strings (each one is unique) and hurt model generalization.\n",
    "  </p>\n",
    "\n",
    "  <h4 style=\"color: #000;\">\n",
    "    üìå <strong>Real-World:</strong>\n",
    "  </h4>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    In a tweet like ‚ÄúCheck this out <span style= color:#ab1700ff;>üëâ https://xyz.com‚Äù</span>, we care more about the sentiment or emotion, not the URL itself.\n",
    "  </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95d0ffdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîµ Original Text:  Visit our website at https://www.example.com/page.html or check out www.another-site.org. You can also find info at mydomain.net/info. \n",
      "\n",
      "üü¢ Text Without URL:  Visit our website at  or check out  You can also find info at \n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "\n",
    "def remove_urls(text):\n",
    "    # Remove all types of URLs from text\n",
    "    if not isinstance(text, str):\n",
    "        print(\"‚ö†Ô∏è Input must be a string.\")\n",
    "        return None\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r'https?://[^\\s/$.?#].[^\\s]*'             # http/https\n",
    "        r'|www\\.[^\\s/$.?#].[^\\s]*'                # www.\n",
    "        r'|[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,6}(/[^\\s]*)?' # domain.com\n",
    "    )\n",
    "    return pattern.sub('', text)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text = \"Visit our website at https://www.example.com/page.html or check out www.another-site.org. You can also find info at mydomain.net/info.\"\n",
    "\n",
    "cleaned_text = remove_urls(text)\n",
    "\n",
    "print(\"üîµ Original Text: \", text, \"\\n\")\n",
    "print(\"üü¢ Text Without URL: \", cleaned_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057d70b1",
   "metadata": {},
   "source": [
    "<div style=\"margin: 2rem auto; padding: 1rem;\">\n",
    "  <hr style=\"border: none; height: 3px; background: linear-gradient(90deg, #4b0000ff, #edf500ff); width: 100%; margin: 1rem 0;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94869298",
   "metadata": {},
   "source": [
    "<div style=\"background:linear-gradient(135deg, #8d8d8dff, #9c9b9bff); border: 3px solid yellow; border-radius: 20px; padding:15px\">\n",
    "\n",
    "  <h2 style=\"font-weight: 700; color: #000;\">\n",
    "    4Ô∏è‚É£ Remove Punctuation\n",
    "  </h2>\n",
    "\n",
    "  <h3 style=\"color: #000;\">\n",
    "    üîç <strong>Why:</strong>\n",
    "  </h3>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    Punctuation marks like \n",
    "    <code style=\"color: #ab1700ff;\">!</code>, \n",
    "    <code style=\"color: #ab1700ff;\">.</code>, \n",
    "    <code style=\"color: #ab1700ff;\">?</code>, \n",
    "    <code style=\"color: #ab1700ff;\">,</code> \n",
    "    create unnecessary tokens.\n",
    "  </p>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    Removing them helps reduce noise, especially in tasks like text classification or topic modeling.\n",
    "  </p>\n",
    "\n",
    "  <h4 style=\"color: #000;\">\n",
    "    üìå <strong>Real-World:</strong>\n",
    "  </h4>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    For spam detection or document classification, punctuation doesn‚Äôt usually help (unless you‚Äôre analyzing writing style).\n",
    "  </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752634f5",
   "metadata": {},
   "source": [
    "| Method                               | Removes ASCII | Removes Unicode | Customizable |\n",
    "| ------------------------------------ | ------------- | --------------- | ------------ |\n",
    "| `string.punctuation` + `translate()` | ‚úÖ Yes         | ‚ùå No            | ‚ùå Limited    |\n",
    "| `re.sub(r'\\p{P}+', '', text)`       | ‚úÖ Yes         | ‚úÖ Yes           | ‚úÖ Yes        |\n",
    "\n",
    "- string.punctuation only covers ASCII punctuation & returns: <div>!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~</div>\n",
    "\n",
    "- Unicode symbols like  `‚Äú`, `‚Äî`, and `‚Ä¶` are not included in string.punctuation, so we need to add them manually or using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b850b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîµ Original Text:  Hello!!! How are you??? I'm fine:) ‚ÄúGreat‚Äù‚Äî yes‚Ä¶ \n",
      "\n",
      "üü¢ Text Without Punctuation:  Hello How are you Im fine Great yes\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    # Remove punctuation from text\n",
    "    if not isinstance(text, str):\n",
    "        print(\"‚ö†Ô∏è Input must be a string.\")\n",
    "        return None\n",
    "\n",
    "    custom_punct = string.punctuation + '‚Äú‚Äù‚Äî‚Ä¶'\n",
    "    return text.translate(str.maketrans('', '', custom_punct))\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text = \"Hello!!! How are you??? I'm fine:) ‚ÄúGreat‚Äù‚Äî yes‚Ä¶\"\n",
    "cleaned_text = remove_punctuation(text)\n",
    "\n",
    "print(\"üîµ Original Text: \", text, \"\\n\")\n",
    "print(\"üü¢ Text Without Punctuation: \", cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad8e9421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîµ Original Text:  Hello!!! How are you??? I'm fine:) ‚ÄúGreat‚Äù‚Äî yes‚Ä¶ \n",
      "\n",
      "üü¢ Text Without Punctuation (Regex):  Hello How are you Im fine Great yes\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "\n",
    "def remove_punctuation_regex(text):\n",
    "    # Remove all punctuation (Unicode-aware)\n",
    "    if not isinstance(text, str):\n",
    "        print(\"‚ö†Ô∏è Input must be a string.\")\n",
    "        return None\n",
    "\n",
    "    return re.sub(r'\\p{P}+', '', text)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text = \"Hello!!! How are you??? I'm fine:) ‚ÄúGreat‚Äù‚Äî yes‚Ä¶\"\n",
    "cleaned_text = remove_punctuation_regex(text)\n",
    "\n",
    "print(\"üîµ Original Text: \", text, \"\\n\")\n",
    "print(\"üü¢ Text Without Punctuation (Regex): \", cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319e21be",
   "metadata": {},
   "source": [
    "<div style=\"margin: 2rem auto; padding: 1rem;\">\n",
    "  <hr style=\"border: none; height: 3px; background: linear-gradient(90deg, #4b0000ff, #edf500ff); width: 100%; margin: 1rem 0;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb852938",
   "metadata": {},
   "source": [
    "<div style=\"background:linear-gradient(135deg, #8d8d8dff, #9c9b9bff); border: 3px solid yellow; border-radius: 20px; padding:15px\">\n",
    "\n",
    "  <h2 style=\"font-weight: 700; color: #000;\">\n",
    "    5Ô∏è‚É£ Chat Word Treatment (e.g., GN ‚Üí Good Night)\n",
    "  </h2>\n",
    "\n",
    "  <h3 style=\"color: #000;\">\n",
    "    üîç <strong>Why:</strong>\n",
    "  </h3>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    Chat language is full of abbreviations: \"lol\", \"idk\", \"smh\".\n",
    "  </p>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    They need to be normalized to standard English for models to understand.\n",
    "  </p>\n",
    "\n",
    "  <h4 style=\"color: #000;\">\n",
    "    üìå <strong>Real-World:</strong>\n",
    "  </h4>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    In customer support or social media, replacing abbreviations like <code style=\"color: #ab1700ff;\">\"brb\"</code> with <code style=\"color: #ab1700ff;\">\"be right back\"</code> helps understand the message better.\n",
    "  </p>\n",
    "\n",
    "  <h4 style=\"color: #000;\">\n",
    "    üó£Ô∏è <strong>Slang Words</strong>\n",
    "  </h4>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    The following three GitHub repositories provide comprehensive lists of slang words and their standard English equivalents. These resources are useful for expanding chat abbreviations (e.g., <code style=\"color: #ab1700ff;\">\"GN\"</code> ‚Üí <code style=\"color: #ab1700ff;\">\"Good Night\"</code>) during text preprocessing\n",
    "  </p>\n",
    "\n",
    "  <ul style=\"color: #000; font-weight: bold; font-size: 1rem;\">\n",
    "    <li><a href=\"https://github.com/ipekdk/abbreviation-list-english\" target=\"_blank\" style=color:#ab1700ff;>Repo1</a></li>\n",
    "    <li><a href=\"https://github.com/bodhwani/NLP-VIT-BOT/blob/master/slangs.csv\" target=\"_blank\" style=color:#ab1700ff;>Repo2</a></li>\n",
    "    <li><a href=\"https://github.com/rishabhverma17/sms_slang_translator/blob/master/slang.txt\" target=\"_blank\" style=color:#ab1700ff;>Comman Slang Words</a></li>\n",
    "  </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79551381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîµ Original Text:  BRB guys, lol this is funny. ttyl! \n",
      "\n",
      "üü¢ Text After Slang Replacement:  Be Right Back guys , Laughing Out Loud this is funny . Talk To You Later !\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Note: Slangs.csv present in the Extra_Materials folder\n",
    "\n",
    "def replace_slangs(text, slang_csv_path):\n",
    "    # Replace slangs using a CSV dictionary and spaCy tokenization\n",
    "    if not isinstance(text, str):\n",
    "        print(\"‚ö†Ô∏è Input must be a string.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        slang_df = pd.read_csv(slang_csv_path)\n",
    "        slang_map = dict(zip(slang_df['Abbr'].str.lower(), slang_df['Fullform']))\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è Error loading slang dictionary:\", e)\n",
    "        return None\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        word = token.text\n",
    "        lower = word.lower()\n",
    "        if lower in slang_map:\n",
    "            tokens.extend(slang_map[lower].split())\n",
    "        else:\n",
    "            tokens.append(word)\n",
    "\n",
    "    return \" \".join(tokens) # The join() method takes all items in an iterable and joins them into one string. A string must be specified as the separator\n",
    "\n",
    "# Example usage\n",
    "text = \"BRB guys, lol this is funny. ttyl!\"\n",
    "slang_csv = \"../Extra_Materials/slangs.csv\"\n",
    "\n",
    "processed = replace_slangs(text, slang_csv)\n",
    "\n",
    "print(\"üîµ Original Text: \", text, \"\\n\")\n",
    "print(\"üü¢ Text After Slang Replacement: \", processed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c83a6d",
   "metadata": {},
   "source": [
    "<div style=\"margin: 2rem auto; padding: 1rem;\">\n",
    "  <hr style=\"border: none; height: 3px; background: linear-gradient(90deg, #4b0000ff, #edf500ff); width: 100%; margin: 1rem 0;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92af2dbc",
   "metadata": {},
   "source": [
    "<div style=\"background:linear-gradient(135deg, #8d8d8dff, #9c9b9bff); border: 3px solid yellow; border-radius: 20px; padding:15px\">\n",
    "\n",
    "  <h2 style=\"font-weight: 700; color: #000;\">\n",
    "    6Ô∏è‚É£ Spelling Correction\n",
    "  </h2>\n",
    "\n",
    "  <h3 style=\"color: #000;\">\n",
    "    üîç <strong>Why:</strong>\n",
    "  </h3>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    Typos are common in user input (especially social media).\n",
    "  </p>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    Words like <code style=\"color: #ab1700ff;\">‚Äúbeleive‚Äù</code> won‚Äôt match <code style=\"color: #ab1700ff;\">‚Äúbelieve‚Äù</code> in dictionaries or embeddings.\n",
    "  </p>\n",
    "\n",
    "  <h4 style=\"color: #000;\">\n",
    "    üìå <strong>Real-World:</strong>\n",
    "  </h4>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    Spell correction boosts chatbot understanding and auto-correction in search bars.\n",
    "  </p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0145f190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîµ Original Text:  I realy love natral language prosesing. \n",
      "\n",
      "üü¢ Autocorrect:  I really love natural language crossing. \n",
      "\n",
      "üî¥ TextBlob:  I really love natural language pressing. \n",
      "\n",
      "üü° PySpellChecker:  I really love natural language prosesing.\n"
     ]
    }
   ],
   "source": [
    "from autocorrect import Speller\n",
    "from textblob import TextBlob\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "def correct_spelling(text, method='autocorrect'):\n",
    "    # Correct spelling using the selected method\n",
    "    if not isinstance(text, str):\n",
    "        print(\"‚ö†Ô∏è Input must be a string.\")\n",
    "        return None\n",
    "\n",
    "    if method == 'autocorrect':\n",
    "        spell = Speller(lang='en')\n",
    "        return spell(text)\n",
    "\n",
    "    elif method == 'textblob':\n",
    "        return str(TextBlob(text).correct())\n",
    "\n",
    "    elif method == 'pyspellchecker':\n",
    "        spellchecker = SpellChecker()\n",
    "        tokens = text.split()\n",
    "        return ' '.join([spellchecker.correction(word) or word for word in tokens])\n",
    "\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Invalid method. Choose from: 'autocorrect', 'textblob', 'pyspellchecker'\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text = \"I realy love natral language prosesing.\"\n",
    "\n",
    "auto = correct_spelling(text, method='autocorrect')\n",
    "blob = correct_spelling(text, method='textblob')\n",
    "pyspell = correct_spelling(text, method='pyspellchecker')\n",
    "\n",
    "print(\"üîµ Original Text: \", text, \"\\n\")\n",
    "print(\"üü¢ Autocorrect: \", auto, \"\\n\")\n",
    "print(\"üî¥ TextBlob: \", blob, \"\\n\")\n",
    "print(\"üü° PySpellChecker: \", pyspell)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e06efd",
   "metadata": {},
   "source": [
    "<div style=\"margin: 2rem auto; padding: 1rem;\">\n",
    "  <hr style=\"border: none; height: 3px; background: linear-gradient(90deg, #4b0000ff, #edf500ff); width: 100%; margin: 1rem 0;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f78e50",
   "metadata": {},
   "source": [
    "<div style=\"background:linear-gradient(135deg, #8d8d8dff, #9c9b9bff); border: 3px solid yellow; border-radius: 20px; padding:15px\">\n",
    "\n",
    "  <h2 style=\"font-weight: 700; color: #000;\">\n",
    "    7Ô∏è‚É£ Remove Stop Words\n",
    "  </h2>\n",
    "\n",
    "  <h3 style=\"color: #000;\">\n",
    "    üîç <strong>Why:</strong>\n",
    "  </h3>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    Stopwords like <code style=\"color: #ab1700ff;\">\"the\"</code>, <code style=\"color: #ab1700ff;\">\"is\"</code>, <code style=\"color: #ab1700ff;\">\"at\"</code> are function words, not content words.\n",
    "  </p>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    Removing them improves focus on important tokens.\n",
    "  </p>\n",
    "\n",
    "  <h4 style=\"color: #000;\">\n",
    "    üìå <strong>Real-World:</strong>\n",
    "  </h4>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    In a movie review, <code style=\"color: #ab1700ff;\">‚ÄúThe movie was absolutely fantastic‚Äù</code>, word <code style=\"color: #ab1700ff;\">‚Äúfantastic‚Äù</code> carries the sentiment, not <code style=\"color: #ab1700ff;\">‚Äúthe‚Äù</code>.\n",
    "  </p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5532e1f",
   "metadata": {},
   "source": [
    "#### **Remove stop words with the help of spacy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fe1c6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîµ Original Text:  He must be going to the market because he has to buy some fruits and vegetables. \n",
      "\n",
      "üü¢ Text Without Stop Words:  going market buy fruits vegetables .\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    # Remove stop words using spaCy\n",
    "    if not isinstance(text, str):\n",
    "        print(\"‚ö†Ô∏è Input must be a string.\")\n",
    "        return None\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.text for token in doc if not token.is_stop]) # is_stop is a boolean attribute of the token object that indicates whether the token is a stop word\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text = \"He must be going to the market because he has to buy some fruits and vegetables.\"\n",
    "cleaned = remove_stopwords(text)\n",
    "\n",
    "print(\"üîµ Original Text: \", text, \"\\n\")\n",
    "print(\"üü¢ Text Without Stop Words: \", cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02af8bf",
   "metadata": {},
   "source": [
    "#### **Remove stop words with the help of NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fe556a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîµ Original Text:  He must be going to the market because he has to buy some fruits and vegetables. \n",
      "\n",
      "üü¢ Text Without Stop Words:  must going market buy fruits vegetables .\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def remove_stopwords_nltk(text):\n",
    "    # Remove stop words using NLTK\n",
    "    if not isinstance(text, str):\n",
    "        print(\"‚ö†Ô∏è Input must be a string.\")\n",
    "        return None\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    filtered = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text = \"He must be going to the market because he has to buy some fruits and vegetables.\"\n",
    "cleaned = remove_stopwords_nltk(text)\n",
    "\n",
    "print(\"üîµ Original Text: \", text, \"\\n\")\n",
    "print(\"üü¢ Text Without Stop Words: \", cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ee8450",
   "metadata": {},
   "source": [
    "### **Why Differences Between NLTK and spaCy Stop Word Removal**\n",
    "| **Aspect**                          | **NLTK**                                                                  | **spaCy**                                                          |\n",
    "| ----------------------------------- | ------------------------------------------------------------------------- | ------------------------------------------------------------------ |\n",
    "| **Stop Word List Size**             | Smaller list (about \\~179 words in English)                               | Larger list (around \\~326 words in `en_core_web_sm`)               |\n",
    "| **Tokenization Dependency**         | Uses `word_tokenize()` ‚Äî may split contractions (`can't` ‚Üí `ca`, `n't`)   | Uses `spaCy` tokenizer ‚Äî more robust with contractions and symbols |\n",
    "| **Customization Needed?**           | Often requires manual addition/removal to match task requirements         | More complete by default but still may require fine-tuning         |\n",
    "| **Default Case Sensitivity**        | Case-sensitive (you must lowercase tokens before comparison)              | Handles case-insensitivity internally with `token.is_stop`         |\n",
    "| **Performance**                     | Lightweight, fast                                                         | Slightly slower due to full NLP pipeline                           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dc3974",
   "metadata": {},
   "source": [
    "<div style=\"margin: 2rem auto; padding: 1rem;\">\n",
    "  <hr style=\"border: none; height: 3px; background: linear-gradient(90deg, #4b0000ff, #edf500ff); width: 100%; margin: 1rem 0;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e680edd1",
   "metadata": {},
   "source": [
    "<div style=\"background:linear-gradient(135deg, #8d8d8dff, #9c9b9bff); border: 3px solid yellow; border-radius: 20px; padding:15px\">\n",
    "\n",
    "  <h2 style=\"font-weight: 700; color: #000;\">\n",
    "    8Ô∏è‚É£ Handling Emojis\n",
    "  </h2>\n",
    "\n",
    "  <h3 style=\"color: #000;\">\n",
    "    üîç <strong>Why:</strong>\n",
    "  </h3>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    Emojis are sentiment-rich tokens \n",
    "    <code style=\"color: #ab1700ff;\">üòä</code>, \n",
    "    <code style=\"color: #ab1700ff;\">üò¢</code>.\n",
    "  </p>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    You can either remove them, convert to words, or use them as features.\n",
    "  </p>\n",
    "\n",
    "  <h4 style=\"color: #000;\">\n",
    "    üìå <strong>Real-World:</strong>\n",
    "  </h4>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    In social media sentiment analysis, \n",
    "    <code style=\"color: #ab1700ff;\">üò†</code> and \n",
    "    <code style=\"color: #ab1700ff;\">‚ù§Ô∏è</code> change the tone completely and must be considered.\n",
    "  </p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2e03834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîµ Original Text: Good job!üëçI‚Äôm so happyüòä \n",
      "\n",
      "üü¢ Text With Handled Emojis: Good job! thumbs up I‚Äôm so happy smiling face with smiling eyes \n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "\n",
    "def handle_emojis(text):\n",
    "    # Convert emojis to text and clean symbols\n",
    "    if not isinstance(text, str):\n",
    "        print(\"‚ö†Ô∏è Input must be a string.\")\n",
    "        return None\n",
    "\n",
    "    text_with_labels = emoji.demojize(text)\n",
    "    cleaned = text_with_labels.replace(':', ' ').replace('_', ' ')\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text = \"Good job!üëçI‚Äôm so happyüòä\"\n",
    "result = handle_emojis(text)\n",
    "\n",
    "print(\"üîµ Original Text:\", text, \"\\n\")\n",
    "print(\"üü¢ Text With Handled Emojis:\", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ee66ec",
   "metadata": {},
   "source": [
    "<div style=\"margin: 2rem auto; padding: 1rem;\">\n",
    "  <hr style=\"border: none; height: 3px; background: linear-gradient(90deg, #4b0000ff, #edf500ff); width: 100%; margin: 1rem 0;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252f43ef",
   "metadata": {},
   "source": [
    "<div style=\"background:linear-gradient(135deg, #8d8d8dff, #9c9b9bff); border: 3px solid yellow; border-radius: 20px; padding:15px\">\n",
    "\n",
    "  <h2 style=\"font-weight: 700; color: #000;\">\n",
    "    9Ô∏è‚É£ Tokenization\n",
    "  </h2>\n",
    "\n",
    "  <h3 style=\"color: #000;\">\n",
    "    ‚ö†Ô∏è <strong>Very Important Step</strong>\n",
    "  </h3>\n",
    "\n",
    "  <h3 style=\"color: #000;\">\n",
    "    üîç <strong>Why:</strong>\n",
    "  </h3>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    Machine learning models in NLP typically require numerical input. Tokenization converts text into a format that can be converted into numerical representations (like word embeddings) that models can understand.\n",
    "  </p>\n",
    "\n",
    "  <h4 style=\"color: #000;\">\n",
    "    üìå <strong>Real-World:</strong>\n",
    "  </h4>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    In the search engine, \n",
    "    <code style=\"color: #ab1700ff;\">\"best Italian restaurants near me\"</code> is tokenized into the words: \n",
    "    <code style=\"color: #ab1700ff;\">[\"best\", \"Italian\", \"restaurants\", \"near\", \"me\"]</code>.\n",
    "  </p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c068731",
   "metadata": {},
   "source": [
    "#### **NLTK vs spaCy Tokenization**\n",
    "\n",
    "| ‚úÖ Feature                      | üü° **NLTK**                           | üîµ **spaCy**                                    |\n",
    "| ------------------------------ | ------------------------------------- | ----------------------------------------------- |\n",
    "| **Model Required**             | No model needed                       | Requires loading a language model               |\n",
    "| **Handles Contractions**       | Yes (e.g. `I'm` ‚Üí `I`, `'m`)          | Yes (e.g. `I'm` ‚Üí `I`, `'m`)                    |\n",
    "| **Handles Punctuation**        | Yes (as separate tokens)              | Yes (more accurate in edge cases)               |\n",
    "| **Emoji, URLs, Hashtags**      | Weak or ignored                       | Strong handling                                 |\n",
    "| **Speed**                      | Very fast (lightweight)               | Slightly slower (loads full NLP model)          |\n",
    "| **Linguistic Context**         | Not available                         | Available (`lemma_`, `pos_`, `ent_type_`, etc.) |\n",
    "| **Multilingual Support**       | Limited (manual setup)                | Built-in via different spaCy models             |\n",
    "| **Integration with NLP Tasks** | Manual (POS, lemma, NER are separate) | Seamless (everything in one pipeline)           |\n",
    "| **Best Use Case**              | Quick, simple preprocessing           | Full-featured NLP pipelines and production apps |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a10828",
   "metadata": {},
   "source": [
    "#### **Tokenization with `spacy.blank(\"en\")` create object (only tokenizer) No lemmatization, NER, POS & Tagging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce2221d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîµ Original Text: Hello, world! This is a test sentence. Let's see how it works. \n",
      "\n",
      "üü¢ Tokenized Text: ['Hello', ',', 'world', '!', 'This', 'is', 'a', 'test', 'sentence', '.', 'Let', \"'s\", 'see', 'how', 'it', 'works', '.']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def tokenize_text(text):\n",
    "    # Tokenize text using spaCy blank English model\n",
    "    if not isinstance(text, str):\n",
    "        print(\"‚ö†Ô∏è Input must be a string.\")\n",
    "        return None\n",
    "\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text = \"Hello, world! This is a test sentence. Let's see how it works.\"\n",
    "tokens = tokenize_text(text)\n",
    "\n",
    "print(\"üîµ Original Text:\", text, \"\\n\")\n",
    "print(\"üü¢ Tokenized Text:\", tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8f7c66",
   "metadata": {},
   "source": [
    "#### **Tokenization with `spacy.load(\"en_core_web_sm\")` small English model (includes tokenizer, POS, NER, etc.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e65bf405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîµ Original Text: Hello, world! This is a test sentence. Let's see how it works. \n",
      "\n",
      "üü¢ Tokenized Text (Full Model): ['Hello', ',', 'world', '!', 'This', 'is', 'a', 'test', 'sentence', '.', 'Let', \"'s\", 'see', 'how', 'it', 'works', '.']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def tokenize_with_model(text):\n",
    "    # Tokenize text using spaCy's full English model\n",
    "    if not isinstance(text, str):\n",
    "        print(\"‚ö†Ô∏è Input must be a string.\")\n",
    "        return None\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text = \"Hello, world! This is a test sentence. Let's see how it works.\"\n",
    "tokens = tokenize_with_model(text)\n",
    "\n",
    "print(\"üîµ Original Text:\", text, \"\\n\")\n",
    "print(\"üü¢ Tokenized Text (Full Model):\", tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56be289f",
   "metadata": {},
   "source": [
    "#### **Tokenization with NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3435aac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîµ Original Text: Hello, world! This is a test sentence. Let's see how it works. \n",
      "\n",
      "üü¢ Tokenized Text (NLTK): ['Hello', ',', 'world', '!', 'This', 'is', 'a', 'test', 'sentence', '.', 'Let', \"'s\", 'see', 'how', 'it', 'works', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenize_nltk(text):\n",
    "    # Tokenize text using NLTK\n",
    "    if not isinstance(text, str):\n",
    "        print(\"‚ö†Ô∏è Input must be a string.\")\n",
    "        return None\n",
    "    return word_tokenize(text)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text = \"Hello, world! This is a test sentence. Let's see how it works.\"\n",
    "tokens = tokenize_nltk(text)\n",
    "\n",
    "print(\"üîµ Original Text:\", text, \"\\n\")\n",
    "print(\"üü¢ Tokenized Text (NLTK):\", tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b63df1",
   "metadata": {},
   "source": [
    "<div style=\"margin: 2rem auto; padding: 1rem;\">\n",
    "  <hr style=\"border: none; height: 3px; background: linear-gradient(90deg, #4b0000ff, #edf500ff); width: 100%; margin: 1rem 0;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8e6015",
   "metadata": {},
   "source": [
    "<div style=\"background:linear-gradient(135deg, #8d8d8dff, #9c9b9bff); border: 3px solid yellow; border-radius: 20px; padding:15px\">\n",
    "\n",
    "  <h2 style=\"font-weight: 700; color: #000;\">\n",
    "    üîü Stemming\n",
    "  </h2>\n",
    "\n",
    "  <h3 style=\"color: #000;\">\n",
    "    üîç <strong>Why:</strong>\n",
    "  </h3>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    Stemming reduces words to a base/root form. It‚Äôs fast and works well in information retrieval systems.\n",
    "  </p>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    May produce non-words (e.g., \n",
    "    <code style=\"color: #ab1700ff;\">‚Äústudies‚Äù</code> ‚Üí \n",
    "    <code style=\"color: #ab1700ff;\">‚Äústudi‚Äù</code>).\n",
    "  </p>\n",
    "\n",
    "  <h4 style=\"color: #000;\">\n",
    "    üìå <strong>Real-World:</strong>\n",
    "  </h4>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    Used in search engines (e.g., \n",
    "    <code style=\"color: #ab1700ff;\">‚Äúsearching‚Äù</code>, \n",
    "    <code style=\"color: #ab1700ff;\">‚Äúsearched‚Äù</code>, \n",
    "    <code style=\"color: #ab1700ff;\">‚Äúsearches‚Äù</code> ‚Üí \n",
    "    <code style=\"color: #ab1700ff;\">‚Äúsearch‚Äù</code>) to show relevant documents.\n",
    "  </p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f86c558",
   "metadata": {},
   "source": [
    "#### **The 3 Main NLTK Stemmers VS Lemmatization**\n",
    "\n",
    "| Technique            | Aggressiveness   | Language Support                 | Speed                     | Output Quality               | Notes                                                               |\n",
    "| -------------------- | ---------------- | -------------------------------- | ------------------------- | ---------------------------- | ------------------------------------------------------------------- |\n",
    "| **PorterStemmer**    | ‚úÖ Moderate       | English only                     | ‚úÖ Fast                    | ‚úÖ Good, widely used          | Most commonly used, balanced stemming algorithm                     |\n",
    "| **LancasterStemmer** | üî• Very high     | English only                     | ‚úÖ Fast                    | ‚ùå Over-stems words           | Very aggressive ‚Üí `maximum` ‚Üí `maxim`                       |\n",
    "| **SnowballStemmer**  | üü¢ Balanced      | ‚úÖ Multiple langs                 | ‚úÖ Fast                    | ‚úÖ Clean, improved            | Also called ‚ÄúPorter2‚Äù ‚Äî better, more consistent than Porter         |\n",
    "| **Lemmatization**    | ‚ùå Not aggressive | ‚úÖ Multiple langs (WordNet/spaCy) | ‚ö†Ô∏è Slower (context-aware) | ‚úÖ Real words & context-aware | Uses grammar + vocabulary, returns meaningful dictionary base forms |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7dd86751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîµ Original Text:  The organization organized organized events efficiently . \n",
      "\n",
      "üü¢ PorterStemmer:  the organ organ organ event effici . \n",
      "\n",
      "üî¥ LancasterStemmer:  the org org org ev efficy . \n",
      "\n",
      "üü° SnowballStemmer:  the organ organ organ event effici . \n",
      "\n",
      "üü£ Lemmatization:  the organization organize organize event efficiently .\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "import spacy\n",
    "\n",
    "# Load spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize stemmers\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "snowball = SnowballStemmer(\"english\")\n",
    "\n",
    "def compare_stemming_lemmatization(text):\n",
    "    # Compare multiple stemmers and lemmatizer\n",
    "    if not isinstance(text, str):\n",
    "        print(\"‚ö†Ô∏è Input must be a string.\")\n",
    "        return None\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    porter_result = [porter.stem(token.text) for token in doc]\n",
    "    lancaster_result = [lancaster.stem(token.text) for token in doc]\n",
    "    snowball_result = [snowball.stem(token.text) for token in doc]\n",
    "    lemmatized_result = [token.lemma_ for token in doc]\n",
    "\n",
    "    return {\n",
    "        \"original\": [token.text for token in doc],\n",
    "        \"porter\": porter_result,\n",
    "        \"lancaster\": lancaster_result,\n",
    "        \"snowball\": snowball_result,\n",
    "        \"lemma\": lemmatized_result\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "text = \"The organization organized organized events efficiently.\"\n",
    "results = compare_stemming_lemmatization(text)\n",
    "\n",
    "# Print results\n",
    "print(\"üîµ Original Text: \", \" \".join(results[\"original\"]), \"\\n\")\n",
    "print(\"üü¢ PorterStemmer: \", \" \".join(results[\"porter\"]), \"\\n\")\n",
    "print(\"üî¥ LancasterStemmer: \", \" \".join(results[\"lancaster\"]), \"\\n\")\n",
    "print(\"üü° SnowballStemmer: \", \" \".join(results[\"snowball\"]), \"\\n\")\n",
    "print(\"üü£ Lemmatization: \", \" \".join(results[\"lemma\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8fc55b",
   "metadata": {},
   "source": [
    "<div style=\"margin: 2rem auto; padding: 1rem;\">\n",
    "  <hr style=\"border: none; height: 3px; background: linear-gradient(90deg, #4b0000ff, #edf500ff); width: 100%; margin: 1rem 0;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5c15c0",
   "metadata": {},
   "source": [
    "<div style=\"background:linear-gradient(135deg, #8d8d8dff, #9c9b9bff); border: 3px solid yellow; border-radius: 20px; padding:15px\">\n",
    "\n",
    "  <h2 style=\"font-weight: 700; color: #000;\">\n",
    "    üî¢ Lemmatization\n",
    "  </h2>\n",
    "\n",
    "  <h3 style=\"color: #000;\">\n",
    "    üîç <strong>Why:</strong>\n",
    "  </h3>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    Like stemming, but linguistically accurate.\n",
    "  </p>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    Uses vocabulary and grammar rules to return the correct base word.\n",
    "  </p>\n",
    "\n",
    "  <h4 style=\"color: #000;\">\n",
    "    üìå <strong>Real-World:</strong>\n",
    "  </h4>\n",
    "  <p style=\"color: #000; font-weight: bold;\">\n",
    "    For grammar-sensitive tasks like question answering or summarization, \n",
    "    <code style=\"color: #ab1700ff;\">‚Äúwas‚Äù</code> should be lemmatized to \n",
    "    <code style=\"color: #ab1700ff;\">‚Äúbe‚Äù</code>, not \n",
    "    <code style=\"color: #ab1700ff;\">‚Äúwa‚Äù</code>.\n",
    "  </p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2227650",
   "metadata": {},
   "source": [
    "#### **Comparison: Lemmatization in spaCy vs NLTK**\n",
    "| Feature           | **spaCy**                         | **NLTK (WordNetLemmatizer)**         |\n",
    "| ----------------- | --------------------------------- | ------------------------------------ |\n",
    "| Accuracy          | ‚úÖ High (uses POS + context)       | ‚ö†Ô∏è Medium (needs manual POS mapping) |\n",
    "| Language model    | `en_core_web_sm` or larger models | WordNet dictionary                   |\n",
    "| POS Tag Awareness | ‚úÖ Automatic                       | ‚ö†Ô∏è Must provide POS manually         |\n",
    "| Output Quality    | ‚úÖ Real, accurate base forms       | ‚úÖ Good, but context-blind sometimes  |\n",
    "| Ease of Use       | ‚úÖ Very easy                       | ‚ö†Ô∏è Slightly complex (POS conversion) |\n",
    "| Performance       | ‚úÖ Fast and optimized              | ‚úÖ Fast but rule-based                |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fecc872",
   "metadata": {},
   "source": [
    "#### **Lemmatization Using Spacy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "489ea81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîµ Original Text: The children were running and better organized events every week. \n",
      "\n",
      "üü¢ After Lemmatization: the child be run and well organize event every week .\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    # Lemmatize text with POS awareness\n",
    "    if not isinstance(text, str):\n",
    "        print(\"‚ö†Ô∏è Input must be a string.\")\n",
    "        return None\n",
    "\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text = \"The children were running and better organized events every week.\"\n",
    "lemmas = lemmatize_text(text)\n",
    "\n",
    "print(\"üîµ Original Text:\", text, \"\\n\")\n",
    "print(\"üü¢ After Lemmatization:\", \" \".join(lemmas))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0013ba",
   "metadata": {},
   "source": [
    "#### **Lemmatization Using NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b0caad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîµ Original Text: The children were running and better organized events every week. \n",
      "\n",
      "üü¢ After Lemmatization: The child be run and good organize event every week .\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "# Map NLTK POS tags to WordNet POS tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    return wordnet.NOUN  # Default to noun\n",
    "\n",
    "def lemmatize_text_nltk(text):\n",
    "    # Lemmatize text using NLTK with POS awareness\n",
    "    if not isinstance(text, str):\n",
    "        print(\"‚ö†Ô∏è Input must be a string.\")\n",
    "        return None\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(text)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    lemmas = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "    return lemmas\n",
    "\n",
    "text = \"The children were running and better organized events every week.\"\n",
    "lemmas = lemmatize_text_nltk(text)\n",
    "\n",
    "print(\"üîµ Original Text:\", text, \"\\n\")\n",
    "print(\"üü¢ After Lemmatization:\", \" \".join(lemmas))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2105d408",
   "metadata": {},
   "source": [
    "<div style=\"margin: 2rem auto; padding: 1rem;\">\n",
    "  <hr style=\"border: none; height: 3px; background: linear-gradient(90deg, #4b0000ff, #edf500ff); width: 100%; margin: 1rem 0;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d646831",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary Table\n",
    "\n",
    "| Step                | Purpose                                                                 | Use Case Examples                                     |\n",
    "|---------------------|-------------------------------------------------------------------------|--------------------------------------------------------|\n",
    "| Lowercasing          | Normalize text casing                                                   | Text classification, search                           |\n",
    "| Remove HTML Tags     | remove unwanted HTML tags                                                | Web scraping, email cleaning                          |\n",
    "| Remove URLs          | Remove unnecessary web links                                             | Social media, forums                                  |\n",
    "| Remove Punctuation   | Clean punctuation noise                                                  | Preprocessing for BoW/TF-IDF                          |\n",
    "| Chat Word Treatment  | Convert slang to standard English like GD to Good Night                  | Chatbots, social media analysis                       |\n",
    "| Spelling Correction  | Fix typos for vocabulary consistency                                     | User reviews, text input                              |\n",
    "| Remove Stop Words    | Focus on meaningful words                                                 | Summarization, topic modeling                         |\n",
    "| Handle Emojis        | Preserve or convert emojis based on task                                | Sentiment analysis                                    |\n",
    "| Tokenization         | Break down text into tokens                                              | All NLP tasks                                         |\n",
    "| Stemming             | Reduce word forms to base/root                                           | Search engines, topic modeling                        |\n",
    "| Lemmatization        | Get accurate root word using grammar                                     | Parsing, QA systems, deep learning models             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824ace14",
   "metadata": {},
   "source": [
    "<div id=\"final-message\" style=\"background: #ffffff; padding: 25px 35px; border-radius: 15px; text-align: center; margin-top: 20px; box-shadow: 0 8px 20px rgba(0, 0, 0, 0.2); max-width: 900px; margin-left: auto; margin-right: auto;\">\n",
    "  <h1 style=\"color: #000; font-family: 'Verdana', sans-serif; font-size: 36px; font-weight: bold; text-shadow: 3px 3px 6px rgba(0, 0, 0, 0.3);\">\n",
    "    <span style=\"border-bottom: 5px solid #ffcc00; padding-bottom: 7px;\"> Thank You for Exploring!</span>\n",
    "  </h1>\n",
    "  <p style=\"color: #000; font-size: 20px; font-weight: bold; line-height: 1.8; margin-top: 15px;\">\n",
    "    Feel free to connect with me or explore more of my work using the platforms below:\n",
    "  </p>\n",
    "  <div style=\"margin-top: 20px; display: flex; flex-wrap: wrap; justify-content: center; gap: 20px;\">\n",
    "    \n",
    "  <a href=\"https://www.linkedin.com/in/yousuf-shah-7ba9492b4/\" style=\"text-decoration: none; color: #0077b5;\">\n",
    "    <div style=\"display: flex; flex-direction: column; align-items: center;\">\n",
    "      <img src=\"https://img.icons8.com/ios-filled/40/0077b5/linkedin.png\" alt=\"LinkedIn\" />\n",
    "      <span style=\"font-size: 14px; margin-top: 5px; font-weight: bold;\">LinkedIn</span>\n",
    "    </div>\n",
    "  </a>\n",
    "\n",
    "  <a href=\"https://github.com/Yousfshah\" style=\"text-decoration: none; color: #333;\">\n",
    "    <div style=\"display: flex; flex-direction: column; align-items: center;\">\n",
    "      <img src=\"https://img.icons8.com/material-outlined/40/000000/github.png\" alt=\"GitHub\" />\n",
    "      <span style=\"font-size: 14px; margin-top: 5px; font-weight: bold;\">GitHub</span>\n",
    "    </div>\n",
    "  </a>\n",
    "\n",
    "  <a href=\"https://www.kaggle.com/yousufshah\" style=\"text-decoration: none; color: #20beff;\">\n",
    "    <div style=\"display: flex; flex-direction: column; align-items: center;\">\n",
    "      <img src=\"https://img.icons8.com/windows/40/20beff/kaggle.png\" alt=\"Kaggle\" />\n",
    "      <span style=\"font-size: 14px; margin-top: 5px; font-weight: bold;\">Kaggle</span>\n",
    "    </div>\n",
    "  </a>\n",
    "\n",
    "  <a href=\"https://yousfshah.github.io/Portfolio_Website/\" style=\"text-decoration: none; color: #333;\">\n",
    "    <div style=\"display: flex; flex-direction: column; align-items: center;\">\n",
    "      <img src=\"https://img.icons8.com/ios-filled/40/000000/domain.png\" alt=\"Website\" />\n",
    "      <span style=\"font-size: 14px; margin-top: 5px; font-weight: bold;\">Website</span>\n",
    "    </div>\n",
    "  </a>\n",
    "\n",
    "  <a href=\"https://yousfshah.github.io/Blogging/\" style=\"text-decoration: none; color: #e64a19;\">\n",
    "    <div style=\"display: flex; flex-direction: column; align-items: center;\">\n",
    "      <img src=\"https://img.icons8.com/ios-filled/40/e64a19/blogger.png\" alt=\"Blog\" />\n",
    "      <span style=\"font-size: 14px; margin-top: 5px; font-weight: bold;\">Blog</span>\n",
    "    </div>\n",
    "  </a>\n",
    "\n",
    "  <a href=\"https://x.com/YousufAnalyst\" style=\"text-decoration: none; color: #1da1f2;\">\n",
    "    <div style=\"display: flex; flex-direction: column; align-items: center;\">\n",
    "      <img src=\"https://img.icons8.com/ios-filled/40/1da1f2/twitterx--v1.png\" alt=\"Twitter (X)\" />\n",
    "      <span style=\"font-size: 14px; margin-top: 5px; font-weight: bold;\">Twitter (X)</span>\n",
    "    </div>\n",
    "  </a>\n",
    "\n",
    "  </div>\n",
    "\n",
    "  <p style=\"color: #000; font-size: 20px; font-weight: bold; line-height: 1.8; margin-top: 20px;\">\n",
    "    Let‚Äôs collaborate to create impactful solutions in the field of data science and beyond!\n",
    "  </p>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP-Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
