{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c8b6d61",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f888d2",
   "metadata": {},
   "source": [
    "## 1️⃣ **Lowercasing**\n",
    "\n",
    "### 🔍 **Why:**\n",
    "- Words like \"Good\", \"GOOD\", and \"good\" are semantically identical but are treated as separate tokens if not lowercased.\n",
    "\n",
    "\n",
    "### 📌 **Real-World:**\n",
    "- In a product review system, \"Excellent\" and \"excellent\" should be considered the same sentiment word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cbb363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔵 Original: Good Morning EVERYONE! Let's Start Our NLP Journey. \n",
      "\n",
      "🟢 Preprocessed: good morning everyone! let's start our nlp journey.\n"
     ]
    }
   ],
   "source": [
    "text = \"Good Morning EVERYONE! Let's Start Our NLP Journey.\"\n",
    "lowercased = text.lower()\n",
    "\n",
    "print(\"🔵 Original:\", text, \"\\n\")\n",
    "print(\"🟢 Preprocessed:\", lowercased)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a091a6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591f3aa0",
   "metadata": {},
   "source": [
    "## 2️⃣ **Remove HTML Tags**\n",
    "\n",
    "### 🔍 **Why:**\n",
    "- HTML is markup used for layout, not meaning.\n",
    "\n",
    "- If you're scraping websites (news, blogs), tags like div tag, span tag add noise.\n",
    "\n",
    "### 📌 **Real-World:**\n",
    "- When extracting articles from news sites, you'll find lots of formatting tags. Models get confused by p tag, a href tag etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebc3360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔵 Original: <div>Hello <b>World</b>! NLP is <i>awesome</i>.</div> \n",
      "\n",
      "🟢 Preprocessed with BS4: Hello World! NLP is awesome. \n",
      "\n",
      "🟢 Preprocessed with regex: Hello World! NLP is awesome.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# sample HTML text\n",
    "text = \"<div>Hello <b>World</b>! NLP is <i>awesome</i>.</div>\"\n",
    "\n",
    "# Using BeautifulSoup to remove HTML tags\n",
    "cleaned = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "# Using regex to remove HTML tags\n",
    "re_pattern = \"<(?:\\\"[^\\\"]*\\\"['\\\"]*|'[^']*'['\\\"]*|[^'\\\">])+>\" # # Remove all HTML tags from a string\n",
    "cleaned_re = re.sub(re_pattern, '', text)\n",
    "# cleaned = cleaned.strip()\n",
    "\n",
    "print(\"🔵 Original:\", text, \"\\n\")\n",
    "print(\"🟢 Preprocessed with BS4:\", cleaned, \"\\n\")\n",
    "print(\"🟢 Preprocessed with regex:\", cleaned_re)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762f8ff7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2316925a",
   "metadata": {},
   "source": [
    "## 3️⃣ **Remove URLs**\n",
    "\n",
    "### 🔍 **Why:**\n",
    "- URLs usually don’t carry semantic meaning.\n",
    "\n",
    "- They are high variance strings (each one is unique) and hurt model generalization.\n",
    "\n",
    "### 📌 **Real-World:**\n",
    "- In a tweet like “Check this out 👉 https://xyz.com”, we care more about the sentiment or emotion, not the URL itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d0ffdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔵 Original: Visit our website at https://www.example.com/page.html or check out www.another-site.org. You can also find info at mydomain.net/info. \n",
      "\n",
      "🟢 Preprocessed: Visit our website at  or check out  You can also find info at \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Example usage:\n",
    "text = \"Visit our website at https://www.example.com/page.html or check out www.another-site.org. You can also find info at mydomain.net/info.\"\n",
    "\n",
    "# Regex pattern to match various URL formats (http, https, www, without scheme)\n",
    "url_pattern = re.compile(\n",
    "    r'https?://[^\\s/$.?#].[^\\s]*'  # Matches http/https URLs\n",
    "    r'|www\\.[^\\s/$.?#].[^\\s]*'    # Matches www. URLs\n",
    "    r'|[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,6}(?:/[^\\s]*)?' # Matches domain-only URLs like example.com\n",
    ")\n",
    "\n",
    "# Remove URLs from the text\n",
    "text_without_urls= url_pattern.sub(r'', text)\n",
    "\n",
    "print(\"🔵 Original:\", text, \"\\n\")\n",
    "print(\"🟢 Preprocessed:\", text_without_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057d70b1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752634f5",
   "metadata": {},
   "source": [
    "## 4️⃣ **Remove Punctuation**\n",
    "\n",
    "### 🔍 **Why:**\n",
    "-  Punctuation marks like `!`, `.`, `?` create unnecessary tokens.\n",
    "\n",
    "- Removing them helps reduce noise, especially in tasks like text classification or topic modeling.\n",
    "\n",
    "### 📌 **Real-World:**\n",
    "- For spam detection or document classification, punctuation doesn’t usually help (unless you’re analyzing writing style)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b850b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔵 Original: (Hello!!! How are you??? I'm fine :) \n",
      "\n",
      "🟢 Preprocessed: Hello How are you Im fine \n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "text = \"Hello!!! How are you??? I'm fine :)\"\n",
    "no_punc = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "print(\"🔵 Original:\", text, \"\\n\")\n",
    "print(\"🟢 Preprocessed:\", no_punc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319e21be",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5094c72",
   "metadata": {},
   "source": [
    "## 5️⃣ **Chat Word Treatment (e.g., GN → Good Night)**\n",
    "\n",
    "### 🔍 **Why:**\n",
    "- Chat language is full of abbreviations: \"lol\", \"idk\", \"smh\".\n",
    "\n",
    "- They need to be normalized to standard English for models to understand.\n",
    "\n",
    "### 📌 **Real-World:**\n",
    "- In customer support or social media, replacing abbreviations like `\"brb\"` with `\"be right back\"` helps understand the message better.\n",
    "\n",
    "### 🗣️ **Slang Words**\n",
    "- The following two GitHub repositories provide comprehensive lists of slang words and their standard English equivalents.These resources are useful for expanding chat abbreviations (e.g., \"GN\" → \"Good Night\") during text preprocessing\n",
    "\n",
    "    - [Repo1](https://github.com/ipekdk/abbreviation-list-english)\n",
    "    - [Repo2](https://github.com/bodhwani/NLP-VIT-BOT/blob/master/slangs.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55030324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔵 Original: BRB guys, lol this is funny. ttyl! \n",
      "\n",
      "🟢 Preprocessed: ['Be Right Back', 'guys,', 'Laughing Out Loud', 'this', 'is', 'funny.', 'Talk To You Later']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the slang abbreviation CSV file\n",
    "chat_dict = pd.read_csv(\"slangs.csv\")\n",
    "\n",
    "# Create a mapping dictionary for fast lookup\n",
    "slang_map = dict(zip(chat_dict['Abbr'].str.lower(), chat_dict['Fullform']))\n",
    "\n",
    "text = \"BRB guys, lol this is funny. ttyl!\"\n",
    "words = text.split()\n",
    "chat_fixed = []\n",
    "for word in words:\n",
    "    key = word.lower().strip(\".,!?\")  # Remove punctuation for matching\n",
    "    if key in slang_map:\n",
    "        chat_fixed.append(slang_map[key])\n",
    "    else:\n",
    "        chat_fixed.append(word)\n",
    "\n",
    "print(\"🔵 Original:\", text, \"\\n\")\n",
    "print(\"🟢 Preprocessed:\", chat_fixed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c83a6d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92af2dbc",
   "metadata": {},
   "source": [
    "## 6️⃣ **Spelling Correction**\n",
    "\n",
    "### 🔍 **Why:**\n",
    "- Typos are common in user input (especially social media).\n",
    "\n",
    "- Words like “beleive” won’t match “believe” in dictionaries or embeddings.\n",
    "\n",
    "### 📌 **Real-World:**\n",
    "- Spell correction boosts chatbot understanding and auto-correction in search bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0145f190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85e06efd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f78e50",
   "metadata": {},
   "source": [
    "## 7️⃣ **Remove Stop Words**\n",
    "\n",
    "### 🔍 **Why:**\n",
    "- Stopwords like \"the\", \"is\", \"at\" are function words, not content words.\n",
    "\n",
    "- Removing them improves focus on important tokens.\n",
    "\n",
    "### 📌 **Real-World:**\n",
    "- In a movie review, “The movie was absolutely fantastic”, word “fantastic” carries the sentiment, not “the”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2c8dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5dc3974",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e680edd1",
   "metadata": {},
   "source": [
    "## 8️⃣ **Handling Emojis**\n",
    "\n",
    "### 🔍 **Why:**\n",
    "- Emojis are sentiment-rich tokens (😊, 😢).\n",
    "\n",
    "- You can either remove them, convert to words, or use them as features.\n",
    "\n",
    "### 📌 **Real-World:**\n",
    "- In social media sentiment analysis, 😠 and ❤️ change the tone completely and must be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e03834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67ee66ec",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252f43ef",
   "metadata": {},
   "source": [
    "## 9️⃣ **Tokenization**\n",
    "\n",
    "### ⚠️ **Very Important Step**\n",
    "\n",
    "### 🔍 **Why:**\n",
    "Machine learning models in NLP typically require numerical input. Tokenization converts text into a format that can be converted into numerical representations (like word embeddings) that models can understand.\n",
    "\n",
    "#### **Example:**\n",
    "Let's say we have the sentence: `The quick brown fox jumps over the lazy dog.`\n",
    "Word Tokenization:\n",
    "> [\"The\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\", \".\"]\n",
    "\n",
    "### 📌 **Real-World:**\n",
    "- In the search engine, \"best Italian restaurants near me\" is tokenized into the words: [\"best\", \"Italian\", \"restaurants\", \"near\", \"me\"]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b63df1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8e6015",
   "metadata": {},
   "source": [
    "## 🔟 **Stemming**\n",
    "\n",
    "### 🔍 **Why:**\n",
    "- Stemming reduces words to a base/root form. It’s fast and works well in information retrieval systems.\n",
    "\n",
    "- May produce non-words (e.g., “studies” → “studi”).\n",
    "\n",
    "### 📌 **Real-World:**\n",
    "- Used in search engines (e.g., “searching”, “searched”, “searches” → “search”) to show relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974b3186",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f8fc55b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5c15c0",
   "metadata": {},
   "source": [
    "## 🔢 **Lemmatization**\n",
    "\n",
    "### 🔍 **Why:**\n",
    "- Like stemming, but linguistically accurate.\n",
    "\n",
    "- Uses vocabulary and grammar rules to return the correct base word.\n",
    "\n",
    "### 📌 **Real-World:**\n",
    "- For grammar-sensitive tasks like question answering or summarization, “was” should be lemmatized to “be”, not “wa”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98194606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d042e66c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP-Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
