{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c8b6d61",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f888d2",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ **Lowercasing**\n",
    "\n",
    "### ğŸ” **Why:**\n",
    "- Words like \"Good\", \"GOOD\", and \"good\" are semantically identical but are treated as separate tokens if not lowercased.\n",
    "\n",
    "\n",
    "### ğŸ“Œ **Real-World:**\n",
    "- In a product review system, \"Excellent\" and \"excellent\" should be considered the same sentiment word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cbb363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”µ Original: Good Morning EVERYONE! Let's Start Our NLP Journey. \n",
      "\n",
      "ğŸŸ¢ Preprocessed: good morning everyone! let's start our nlp journey.\n"
     ]
    }
   ],
   "source": [
    "text = \"Good Morning EVERYONE! Let's Start Our NLP Journey.\"\n",
    "lowercased = text.lower()\n",
    "\n",
    "print(\"ğŸ”µ Original:\", text, \"\\n\")\n",
    "print(\"ğŸŸ¢ Preprocessed:\", lowercased)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a091a6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591f3aa0",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ **Remove HTML Tags**\n",
    "\n",
    "### ğŸ” **Why:**\n",
    "- HTML is markup used for layout, not meaning.\n",
    "\n",
    "- If you're scraping websites (news, blogs), tags like div tag, span tag add noise.\n",
    "\n",
    "### ğŸ“Œ **Real-World:**\n",
    "- When extracting articles from news sites, you'll find lots of formatting tags. Models get confused by p tag, a href tag etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebc3360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”µ Original: <div>Hello <b>World</b>! NLP is <i>awesome</i>.</div> \n",
      "\n",
      "ğŸŸ¢ Preprocessed with BS4: Hello World! NLP is awesome. \n",
      "\n",
      "ğŸŸ¢ Preprocessed with regex: Hello World! NLP is awesome.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# sample HTML text\n",
    "text = \"<div>Hello <b>World</b>! NLP is <i>awesome</i>.</div>\"\n",
    "\n",
    "# Using BeautifulSoup to remove HTML tags\n",
    "cleaned = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "# Using regex to remove HTML tags\n",
    "re_pattern = \"<(?:\\\"[^\\\"]*\\\"['\\\"]*|'[^']*'['\\\"]*|[^'\\\">])+>\" # # Remove all HTML tags from a string\n",
    "cleaned_re = re.sub(re_pattern, '', text)\n",
    "# cleaned = cleaned.strip()\n",
    "\n",
    "print(\"ğŸ”µ Original:\", text, \"\\n\")\n",
    "print(\"ğŸŸ¢ Preprocessed with BS4:\", cleaned, \"\\n\")\n",
    "print(\"ğŸŸ¢ Preprocessed with regex:\", cleaned_re)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762f8ff7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2316925a",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ **Remove URLs**\n",
    "\n",
    "### ğŸ” **Why:**\n",
    "- URLs usually donâ€™t carry semantic meaning.\n",
    "\n",
    "- They are high variance strings (each one is unique) and hurt model generalization.\n",
    "\n",
    "### ğŸ“Œ **Real-World:**\n",
    "- In a tweet like â€œCheck this out ğŸ‘‰ https://xyz.comâ€, we care more about the sentiment or emotion, not the URL itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d0ffdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”µ Original: Visit our website at https://www.example.com/page.html or check out www.another-site.org. You can also find info at mydomain.net/info. \n",
      "\n",
      "ğŸŸ¢ Preprocessed: Visit our website at  or check out  You can also find info at \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Example usage:\n",
    "text = \"Visit our website at https://www.example.com/page.html or check out www.another-site.org. You can also find info at mydomain.net/info.\"\n",
    "\n",
    "# Regex pattern to match various URL formats (http, https, www, without scheme)\n",
    "url_pattern = re.compile(\n",
    "    r'https?://[^\\s/$.?#].[^\\s]*'  # Matches http/https URLs\n",
    "    r'|www\\.[^\\s/$.?#].[^\\s]*'    # Matches www. URLs\n",
    "    r'|[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,6}(?:/[^\\s]*)?' # Matches domain-only URLs like example.com\n",
    ")\n",
    "\n",
    "# Remove URLs from the text\n",
    "text_without_urls= url_pattern.sub(r'', text)\n",
    "\n",
    "print(\"ğŸ”µ Original:\", text, \"\\n\")\n",
    "print(\"ğŸŸ¢ Preprocessed:\", text_without_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057d70b1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752634f5",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ **Remove Punctuation**\n",
    "\n",
    "### ğŸ” **Why:**\n",
    "-  Punctuation marks like `!`, `.`, `?` create unnecessary tokens.\n",
    "\n",
    "- Removing them helps reduce noise, especially in tasks like text classification or topic modeling.\n",
    "\n",
    "### ğŸ“Œ **Real-World:**\n",
    "- For spam detection or document classification, punctuation doesnâ€™t usually help (unless youâ€™re analyzing writing style)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b850b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”µ Original: (Hello!!! How are you??? I'm fine :) \n",
      "\n",
      "ğŸŸ¢ Preprocessed: Hello How are you Im fine \n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "text = \"Hello!!! How are you??? I'm fine :)\"\n",
    "no_punc = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "print(\"ğŸ”µ Original:\", text, \"\\n\")\n",
    "print(\"ğŸŸ¢ Preprocessed:\", no_punc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319e21be",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5094c72",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ **Chat Word Treatment (e.g., GN â†’ Good Night)**\n",
    "\n",
    "### ğŸ” **Why:**\n",
    "- Chat language is full of abbreviations: \"lol\", \"idk\", \"smh\".\n",
    "\n",
    "- They need to be normalized to standard English for models to understand.\n",
    "\n",
    "### ğŸ“Œ **Real-World:**\n",
    "- In customer support or social media, replacing abbreviations like `\"brb\"` with `\"be right back\"` helps understand the message better.\n",
    "\n",
    "### ğŸ—£ï¸ **Slang Words**\n",
    "- The following two GitHub repositories provide comprehensive lists of slang words and their standard English equivalents.These resources are useful for expanding chat abbreviations (e.g., \"GN\" â†’ \"Good Night\") during text preprocessing\n",
    "\n",
    "    - [Repo1](https://github.com/ipekdk/abbreviation-list-english)\n",
    "    - [Repo2](https://github.com/bodhwani/NLP-VIT-BOT/blob/master/slangs.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55030324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”µ Original: BRB guys, lol this is funny. ttyl! \n",
      "\n",
      "ğŸŸ¢ Preprocessed: ['Be Right Back', 'guys,', 'Laughing Out Loud', 'this', 'is', 'funny.', 'Talk To You Later']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the slang abbreviation CSV file\n",
    "chat_dict = pd.read_csv(\"slangs.csv\")\n",
    "\n",
    "# Create a mapping dictionary for fast lookup\n",
    "slang_map = dict(zip(chat_dict['Abbr'].str.lower(), chat_dict['Fullform']))\n",
    "\n",
    "text = \"BRB guys, lol this is funny. ttyl!\"\n",
    "words = text.split()\n",
    "chat_fixed = []\n",
    "for word in words:\n",
    "    key = word.lower().strip(\".,!?\")  # Remove punctuation for matching\n",
    "    if key in slang_map:\n",
    "        chat_fixed.append(slang_map[key])\n",
    "    else:\n",
    "        chat_fixed.append(word)\n",
    "\n",
    "print(\"ğŸ”µ Original:\", text, \"\\n\")\n",
    "print(\"ğŸŸ¢ Preprocessed:\", chat_fixed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c83a6d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92af2dbc",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ **Spelling Correction**\n",
    "\n",
    "### ğŸ” **Why:**\n",
    "- Typos are common in user input (especially social media).\n",
    "\n",
    "- Words like â€œbeleiveâ€ wonâ€™t match â€œbelieveâ€ in dictionaries or embeddings.\n",
    "\n",
    "### ğŸ“Œ **Real-World:**\n",
    "- Spell correction boosts chatbot understanding and auto-correction in search bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0145f190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85e06efd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f78e50",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ **Remove Stop Words**\n",
    "\n",
    "### ğŸ” **Why:**\n",
    "- Stopwords like \"the\", \"is\", \"at\" are function words, not content words.\n",
    "\n",
    "- Removing them improves focus on important tokens.\n",
    "\n",
    "### ğŸ“Œ **Real-World:**\n",
    "- In a movie review, â€œThe movie was absolutely fantasticâ€, word â€œfantasticâ€ carries the sentiment, not â€œtheâ€."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2c8dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5dc3974",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e680edd1",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ **Handling Emojis**\n",
    "\n",
    "### ğŸ” **Why:**\n",
    "- Emojis are sentiment-rich tokens (ğŸ˜Š, ğŸ˜¢).\n",
    "\n",
    "- You can either remove them, convert to words, or use them as features.\n",
    "\n",
    "### ğŸ“Œ **Real-World:**\n",
    "- In social media sentiment analysis, ğŸ˜  and â¤ï¸ change the tone completely and must be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e03834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67ee66ec",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252f43ef",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ **Tokenization**\n",
    "\n",
    "### âš ï¸ **Very Important Step**\n",
    "\n",
    "### ğŸ” **Why:**\n",
    "Machine learning models in NLP typically require numerical input. Tokenization converts text into a format that can be converted into numerical representations (like word embeddings) that models can understand.\n",
    "\n",
    "#### **Example:**\n",
    "Let's say we have the sentence: `The quick brown fox jumps over the lazy dog.`\n",
    "Word Tokenization:\n",
    "> [\"The\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\", \".\"]\n",
    "\n",
    "### ğŸ“Œ **Real-World:**\n",
    "- In the search engine, \"best Italian restaurants near me\" is tokenized into the words: [\"best\", \"Italian\", \"restaurants\", \"near\", \"me\"]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b63df1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8e6015",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ **Stemming**\n",
    "\n",
    "### ğŸ” **Why:**\n",
    "- Stemming reduces words to a base/root form. Itâ€™s fast and works well in information retrieval systems.\n",
    "\n",
    "- May produce non-words (e.g., â€œstudiesâ€ â†’ â€œstudiâ€).\n",
    "\n",
    "### ğŸ“Œ **Real-World:**\n",
    "- Used in search engines (e.g., â€œsearchingâ€, â€œsearchedâ€, â€œsearchesâ€ â†’ â€œsearchâ€) to show relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974b3186",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f8fc55b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5c15c0",
   "metadata": {},
   "source": [
    "## ğŸ”¢ **Lemmatization**\n",
    "\n",
    "### ğŸ” **Why:**\n",
    "- Like stemming, but linguistically accurate.\n",
    "\n",
    "- Uses vocabulary and grammar rules to return the correct base word.\n",
    "\n",
    "### ğŸ“Œ **Real-World:**\n",
    "- For grammar-sensitive tasks like question answering or summarization, â€œwasâ€ should be lemmatized to â€œbeâ€, not â€œwaâ€."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98194606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d042e66c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP-Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
